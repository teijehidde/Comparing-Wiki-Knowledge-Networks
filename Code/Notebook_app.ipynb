{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Setup packages\n",
    "import os\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "import collections \n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# all these network algorithms are currently being tried out. \n",
    "import networkx as nx\n",
    "from networkx.algorithms import approximation\n",
    "from networkx.algorithms import community\n",
    "from networkx.algorithms.community import k_clique_communities\n",
    "from networkx.algorithms.community import greedy_modularity_communities\n",
    "from networkx.utils import not_implemented_for \n",
    "__all__ = [\n",
    "    \"eccentricity\",\n",
    "    \"diameter\",\n",
    "    \"radius\",\n",
    "    \"periphery\",\n",
    "    \"center\",\n",
    "    \"barycenter\",\n",
    "    \"degree_centrality\",\n",
    "    \"constraint\", \n",
    "    \"local_constraint\", \n",
    "    \"effective_size\"\n",
    "]\n",
    "\n",
    "\n",
    "# For network visualization: \n",
    "from pyvis.network import Network\n",
    "# use dynetx for dynamic network visualization? -- when I can download and incoporate revision history? \n",
    "\n",
    "PATH = \"/home/teijehidde/Documents/Git Blog and Coding/data_dump/\"\n",
    "DATA_FILE = \"DATA.json\" \n",
    "\n",
    "# Loading JSON file: \n",
    "with open(PATH + DATA_FILE) as json_file:\n",
    "    network_data = json.load(json_file)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "def SaveData(wiki_data, node_title, lang):\n",
    "    # step 1: transforming data from API into unified dictionary. \n",
    "    # 1a: creating list of available nodes. \n",
    "    all_nodes = []\n",
    "\n",
    "    for item in wiki_data:\n",
    "        all_nodes = all_nodes + list(item['query']['pages'].keys())\n",
    "    all_nodes = list(set(all_nodes))\n",
    "\n",
    "    # 1b: Using all_nodes to go through raw data from API -- in this case this should just by 1 node. \n",
    "    for node in all_nodes:\n",
    "        node_data = {'node_ID': node, 'title': '', 'links': [], 'ego': [], 'language': lang, 'AvailableLanguages': []}\n",
    "        \n",
    "        item_name = lang + node\n",
    "        if item_name in network_data.keys():\n",
    "            node_data = network_data[item_name]\n",
    "        \n",
    "        for item in wiki_data:\n",
    "            if node in item['query']['pages'].keys(): \n",
    "                node_data['title'] = item['query']['pages'][node]['title']\n",
    "\n",
    "                if 'links' in item['query']['pages'][node].keys():\n",
    "                    for link in item['query']['pages'][node]['links']: \n",
    "                        node_data['links'].append(link['title'])\n",
    "\n",
    "                if 'langlinks' in item['query']['pages'][node].keys():\n",
    "                    node_data['AvailableLanguages'] = item['query']['pages'][node]['langlinks']\n",
    "\n",
    "                node_data['ego'].append(node_title)\n",
    "        \n",
    "        node_data['ego'] = list(set(node_data['ego']))\n",
    "        \n",
    "        network_data[lang + node] = node_data\n",
    "\n",
    "    # Step 2: Saving data to json file. \n",
    "    try: \n",
    "        with open(PATH + DATA_FILE, 'w') as outfile:\n",
    "            json.dump(network_data, outfile)\n",
    "            print(\"Data succesfully saved. Wiki node name: \" + node_title + \"; downloaded in language: \" + lang + \".\")\n",
    "\n",
    "    except: \n",
    "        print(\"Something went wrong. Check code.\")\n",
    "\n",
    "# optional, for debugging: \n",
    "#   finally:\n",
    "#       return wiki_data\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# Function: download additional languages of ego network.\n",
    "def downloadAdditionalLanguage(node_title, original_lang, additional_langs = []): # \"de\", \"fr\", \"nl\"\n",
    "\n",
    "    # download data fro JSON file. \n",
    "    with open(PATH + DATA_FILE) as json_file:\n",
    "        network_data = json.load(json_file)\n",
    "    \n",
    "    # make a list of the language that are available for requested page. \n",
    "    available_languages = [v['AvailableLanguages'] for (k,v) in network_data.items() if v['title'] == node_title if v['language'] == original_lang][0]\n",
    "    list_available_languages = []\n",
    "    for item in available_languages: \n",
    "         list_available_languages.append(item['lang'])\n",
    "\n",
    "    # If no languages are requested, the function shows available languages. \n",
    "    if additional_langs == []:\n",
    "        pass\n",
    "\n",
    "    if additional_langs == [\"available_langs\"]:\n",
    "        print('The wikipedia page is available in the following languages:')         \n",
    "        print(list_available_languages)\n",
    "    \n",
    "    # Goes through avialble languages of a wikipedia page, and downloads those that were requested (using the downloadNetwork() function). \n",
    "    else:\n",
    "        for item in available_languages: \n",
    "            if item['lang'] in additional_langs:\n",
    "                downloadNetworks(node_title = item['*'], original_lang = item['lang'], additional_langs = [])\n",
    "    \n",
    "        print(\"Download of additional languages finished.\") \n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# Function: download data on links from ALL PAGES linked to 'node_title' \n",
    "def downloadNetworks(node_title, original_lang = \"en\", additional_langs = [\"ar\" \"de\", \"fr\", \"nl\"]): \n",
    "\n",
    "    # setup and load existing data node.\n",
    "    API_ENDPOINT = \"https://\" + original_lang + \".wikipedia.org/w/api.php\" # fr.wikipedia.org; https://en.wikipedia.org\n",
    "    wiki_data = []\n",
    "\n",
    "    # step 1: download data on the central node of the network (incl. available languages). \n",
    "    # setup API query and initial API call \n",
    "    S = requests.Session()\n",
    "    PARAMS = {\n",
    "        \"action\": \"query\",\n",
    "        \"titles\": node_title,\n",
    "        \"prop\": \"links|info|langlinks\",\n",
    "        \"plnamespace\": 0, \n",
    "        \"pllimit\": 500,\n",
    "        \"lllimit\": 500, \n",
    "        \"format\": \"json\"\n",
    "    }\n",
    "    response = S.get(url=API_ENDPOINT, params=PARAMS)\n",
    "    wiki_data.append(response.json())\n",
    "    \n",
    "    # Continue API call until all data on ego node has been downloaded. \n",
    "    while 'continue' in wiki_data[-1].keys():\n",
    "        \n",
    "        PARAMS_CONT = PARAMS\n",
    "        PARAMS_CONT[\"plcontinue\"] = wiki_data[-1]['continue']['plcontinue']\n",
    "\n",
    "        response = S.get(url=API_ENDPOINT, params=PARAMS_CONT)\n",
    "        wiki_data.append(response.json())\n",
    "\n",
    "    # step 2: use generator to download data on all additional nodes. \n",
    "    # setup API query for first generator API call (used to download data on all pages that are linked to node_title) \n",
    "    print(\"Downloading Wiki network name: \" + node_title + \" in language: \" + original_lang + \". Please note that this can take a while.\")\n",
    "    S = requests.Session()\n",
    "    PARAMS = {\n",
    "        \"action\": \"query\",\n",
    "        \"generator\": \"links\",\n",
    "        \"titles\": node_title,\n",
    "        \"gplnamespace\": 0, \n",
    "        \"gpllimit\": 500, \n",
    "        \"plnamespace\": 0,\n",
    "        \"pllimit\": 500, \n",
    "        \"prop\": \"links|info|langlinks\",\n",
    "        \"format\": \"json\"\n",
    "    }\n",
    "    response = S.get(url=API_ENDPOINT, params=PARAMS)\n",
    "    wiki_data.append(response.json())\n",
    "\n",
    "    # Continue API call until all data on network is downloaded. \n",
    "    while 'continue' in wiki_data[-1].keys():\n",
    "\n",
    "        PARAMS_CONT = PARAMS\n",
    "        if 'plcontinue' in wiki_data[-1]['continue']:\n",
    "            PARAMS_CONT[\"plcontinue\"] = wiki_data[-1]['continue']['plcontinue'] \n",
    "\n",
    "        if 'gplcontinue' in wiki_data[-1]['continue']: \n",
    "            PARAMS_CONT[\"gplcontinue\"] = wiki_data[-1]['continue']['gplcontinue']\n",
    "\n",
    "        response = S.get(url=API_ENDPOINT, params = PARAMS_CONT)\n",
    "        wiki_data.append(response.json())\n",
    "\n",
    "    # step 3: transform and save data:  \n",
    "    SaveData(wiki_data, node_title=node_title, lang=original_lang)\n",
    "\n",
    "    # step 4: download additional languages: \n",
    "    downloadAdditionalLanguage(node_title = node_title, original_lang = original_lang, additional_langs = additional_langs)\n",
    "\n",
    "    return wiki_data\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# function: provide titles of networks that are saved in the JSON file. Also provides the language they were saved in. \n",
    "def getDownloadedNetworks(): \n",
    "\n",
    "    # download data from JSON file. \n",
    "    with open(PATH + DATA_FILE) as json_file:\n",
    "        network_data = json.load(json_file)\n",
    "    \n",
    "    # create set of ego network names.  \n",
    "    downloaded_networks = [(v['ego']) for (k,v) in network_data.items()]\n",
    "    downloaded_networks = set(list(chain(*downloaded_networks)))\n",
    "    downloaded_networks = [v for (k,v) in network_data.items() if v['title'] in downloaded_networks]\n",
    "\n",
    "    # print names of ego networks and language that they have been downloaded in. \n",
    "    items = {}  \n",
    "    for network in downloaded_networks: \n",
    "        items[network['title'] + ' (' + network['language'] + ')'] = {'lang':  network['language'], '*': network['title']}    \n",
    "    return(items)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def degree_centrality(G):\n",
    "# copy-pasted from: https://networkx.org/documentation/stable/_modules/networkx/algorithms/centrality/degree_alg.html#degree_centrality\n",
    "    \n",
    "    if len(G) <= 1:\n",
    "        return {n: 1 for n in G}\n",
    "\n",
    "    s = 1.0 / (len(G) - 1.0)\n",
    "    centrality = {n: d * s for n, d in G.degree()}\n",
    "    return centrality\n",
    "\n",
    "def eccentricity(G, v=None, sp=None):\n",
    "# copy-pasted from: https://networkx.org/documentation/stable/_modules/networkx/algorithms/distance_measures.html#eccentricity\n",
    "\n",
    "    order = G.order()\n",
    "\n",
    "    e = {}\n",
    "    for n in G.nbunch_iter(v):\n",
    "        if sp is None:\n",
    "            length = nx.single_source_shortest_path_length(G, n)\n",
    "            L = len(length)\n",
    "        else:\n",
    "            try:\n",
    "                length = sp[n]\n",
    "                L = len(length)\n",
    "            except TypeError as e:\n",
    "                raise nx.NetworkXError('Format of \"sp\" is invalid.') from e\n",
    "        if L != order:\n",
    "            if G.is_directed():\n",
    "                msg = (\n",
    "                    \"Found infinite path length because the digraph is not\"\n",
    "                    \" strongly connected\"\n",
    "                )\n",
    "            else:\n",
    "                msg = \"Found infinite path length because the graph is not\" \" connected\"\n",
    "            raise nx.NetworkXError(msg)\n",
    "\n",
    "        e[n] = max(length.values())\n",
    "\n",
    "    if v in G:\n",
    "        return e[v]  # return single value\n",
    "    else:\n",
    "        return e\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Initiate class Node. \n",
    "class WikiNode:\n",
    "    def __init__(self, node_title, lang):\n",
    "        \n",
    "        # Select node in JSON file (by title and language). \n",
    "        node_data = [v for (k,v) in network_data.items() if v['title'] == node_title if v['language'] == lang][0]\n",
    "        \n",
    "        # Extract data and place in instance of Wikinode class. \n",
    "        self.node_title = node_data['title']\n",
    "        self.node_ID = node_data['node_ID']\n",
    "        self.node_links = node_data['links']\n",
    "        self.node_lang = node_data['language']\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# Initiate class WikiNetwork\n",
    "class WikiNetwork(WikiNode):\n",
    "   \n",
    "    def __init__(self,node_title, lang):\n",
    "        \n",
    "        # initiate the central node of the network as class WikiNode, add additional attributes for class WikiNetwork \n",
    "        WikiNode.__init__(self, node_title, lang)\n",
    "        self.network_nodes = {}\n",
    "        self.network_links = []\n",
    "        self.network_edges = [] \n",
    "        self.network_status = []\n",
    "    \n",
    "        # Go through node_links of the central node (node_title) to build network.\n",
    "        for link in self.node_links + [self.node_title]: \n",
    "            try:     \n",
    "                Node2 = WikiNode(link, lang)             \n",
    "                purged_links = [x for x in Node2.node_links if x in self.node_links]\n",
    "                purged_edges = []\n",
    "                for purged_link in purged_links:\n",
    "                    purged_edges.append((link,purged_link))  \n",
    "                self.network_nodes[Node2.node_ID] = Node2\n",
    "                self.network_links = self.network_links + purged_links\n",
    "                self.network_edges = self.network_edges + purged_edges\n",
    "            except: \n",
    "                print('Loading of node ' + link + ' failed.')\n",
    "        \n",
    "        self.links_count = Counter(self.network_links)\n",
    "\n",
    "    def getNodes(self, type=\"cytoscape\", threshold=0):\n",
    "        selected_nodes = [k for k,v in self.links_count.items() if float(v) >= threshold]\n",
    "        \n",
    "        if type == 'networkx':\n",
    "            return [(i, {\"name\": i}) for i in selected_nodes]\n",
    "\n",
    "        if type == 'cytoscape':\n",
    "            return [{'data': {'id': i, \"label\": i}} for i in selected_nodes]\n",
    "\n",
    "    def getEdges(self,type=\"cytoscape\", threshold=0):  \n",
    "        selected_nodes = [k for k,v in self.links_count.items() if float(v) >= threshold]\n",
    "        edges_network = [(a,b) for a,b in self.network_edges if a in selected_nodes and b in selected_nodes]\n",
    "\n",
    "        if type == 'networkx':\n",
    "            return edges_network\n",
    "\n",
    "        if type == 'cytoscape':\n",
    "            return [{'data': {'source': a, \"target\": b}} for a,b in edges_network]\n",
    "    \n",
    "    def getCommunities(self,threshold=0):  \n",
    "        G = nx.Graph()\n",
    "        G.add_edges_from(self.getEdges(type = 'networkx', threshold= threshold))\n",
    "        return greedy_modularity_communities(G)\n",
    "\n",
    "    def getStatsNodes(self,threshold=0):\n",
    "    # I think this will work much better with pandas... For next sprint. (see: https://stackoverflow.com/questions/46711557/calculating-min-and-max-over-a-list-of-dictionaries-for-normalizing-dictionary-v)\n",
    "        G = nx.Graph()\n",
    "        G.add_edges_from(self.getEdges(type = 'networkx', threshold= threshold))\n",
    "\n",
    "        data = {}\n",
    "        degree_centrality_nodes = degree_centrality(G)\n",
    "        eccentricity_nodes = eccentricity(G)\n",
    "\n",
    "        for item in G.nodes: \n",
    "            data[item] = {'Centrality': round(degree_centrality_nodes[item], 4), 'Eccentricity': eccentricity_nodes[item]} \n",
    "\n",
    "        return(data)\n",
    "    \n",
    "    def getStatsCommunities(self, node):\n",
    "        # TODO: return an numpy array with stats per node: \n",
    "        # Algorithms to consider (see networkx):\n",
    "        # - Distance measures: barycenter, center, [ALSO APPLY TO COMMUNITIES?]\n",
    "        # - dominating_set(G, start_with=None) [ALSO APPLY TO COMMUNITIES?]\n",
    "        # - Group Centrality\n",
    "        # - ... \n",
    "        # if nodes == None: \n",
    "          #  node = self.node_links\n",
    "\n",
    "        print('WIP')\n",
    "    \n",
    "    def getStatsNetwork(self): \n",
    "        return(\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"A\": self.node_ID,\n",
    "                    \"B\": pd.Timestamp(\"20200102\"),\n",
    "                    \"C\": pd.Series(1, index=list(range(4)), dtype=\"float32\"),\n",
    "                    \"D\": np.array([3] * 4, dtype=\"int32\"),\n",
    "                    \"E\": pd.Categorical([\"test\", \"train\", \"test\", \"train\"]),\n",
    "                    \"F\": self.node_title,\n",
    "                }\n",
    "                )\n",
    "            )   \n",
    "        # TODO: return a dictionary with stats on network: \n",
    "        # Algorithms to consider (see networkx):\n",
    "        # - number nodes, number edges, average edges per node. \n",
    "        # - Distance measures: barycenter, center, [ALSO APPLY TO COMMUNITIES?]\n",
    "        # - dominating_set(G, start_with=None) [ALSO APPLY TO COMMUNITIES?]\n",
    "        # - node_connectivity\n",
    "        # - k_components\n",
    "        # - average_clustering\n",
    "        # - Small-world\n",
    "        # - Summarization [NB - possibly use to improve render time graph visualizations.]\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "########################################\n",
    "########################################\n",
    "# FROM HERE RUN TIME STARTS # "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "all_networks = getDownloadedNetworks()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# test download. \n",
    "test = downloadNetworks(node_title=\"Cambridge\", original_lang=\"fr\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading Wiki network name: Cambridge in language: fr. Please note that this can take a while.\n",
      "Data succesfully saved. Wiki node name: Cambridge; downloaded in language: fr.\n",
      "Downloading Wiki network name: Cambridge (Verenigd Koninkrijk) in language: nl. Please note that this can take a while.\n",
      "Data succesfully saved. Wiki node name: Cambridge (Verenigd Koninkrijk); downloaded in language: nl.\n",
      "Download of additional languages finished.\n",
      "Download of additional languages finished.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "source": [
    "# turning wikipedia API output into a list of panda dataframes \n",
    "df = [pd.DataFrame.from_dict(item['query']['pages']).transpose() for item in test]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "source": [
    "# merging all these dataframes into one, using 'update' method. \n",
    "# note that does not work yet for intiial node, because different data (columns) were downloaded. I need to download langlinks and info for all nodes. Using zip to make files smaller.  \n",
    "for item in df: \n",
    "    df[1].update(item)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "source": [
    "# the resulting df is the one on which the 'update' method was run. \n",
    "df_result = df[1]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ns                                                         0\n",
       "title                               Chichester (Royaume-Uni)\n",
       "missing                                                  NaN\n",
       "pageid                                                769145\n",
       "links      [{'ns': 0, 'title': 'Aberdeen'}, {'ns': 0, 'ti...\n",
       "Name: 769145, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 141
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "source": [
    "result = pd.concat(test3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "source": [
    "result"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         contentmodel                                          langlinks  \\\n",
       "15789        wikitext  [{'lang': 'af', '*': 'Cambridge'}, {'lang': 'a...   \n",
       "-1                NaN                                                NaN   \n",
       "-2                NaN                                                NaN   \n",
       "-3                NaN                                                NaN   \n",
       "-4                NaN                                                NaN   \n",
       "...               ...                                                ...   \n",
       "40398             NaN                                                NaN   \n",
       "10300             NaN                                                NaN   \n",
       "27816             NaN                                                NaN   \n",
       "11495371          NaN                                                NaN   \n",
       "1377936           NaN                                                NaN   \n",
       "\n",
       "          lastrevid length                                              links  \\\n",
       "15789     179254172  17453  [{'ns': 0, 'title': '1025'}, {'ns': 0, 'title'...   \n",
       "-1              NaN    NaN                                                NaN   \n",
       "-2              NaN    NaN                                                NaN   \n",
       "-3              NaN    NaN                                                NaN   \n",
       "-4              NaN    NaN                                                NaN   \n",
       "...             ...    ...                                                ...   \n",
       "40398           NaN    NaN                                                NaN   \n",
       "10300           NaN    NaN                                                NaN   \n",
       "27816           NaN    NaN                                                NaN   \n",
       "11495371        NaN    NaN  [{'ns': 0, 'title': 'Accolade (architecture)'}...   \n",
       "1377936         NaN    NaN                                                NaN   \n",
       "\n",
       "         ns    pageid pagelanguage pagelanguagedir pagelanguagehtmlcode  \\\n",
       "15789     0     15789           fr             ltr                   fr   \n",
       "-1        0       NaN          NaN             NaN                  NaN   \n",
       "-2        0       NaN          NaN             NaN                  NaN   \n",
       "-3        0       NaN          NaN             NaN                  NaN   \n",
       "-4        0       NaN          NaN             NaN                  NaN   \n",
       "...      ..       ...          ...             ...                  ...   \n",
       "40398     0     40398          NaN             NaN                  NaN   \n",
       "10300     0     10300          NaN             NaN                  NaN   \n",
       "27816     0     27816          NaN             NaN                  NaN   \n",
       "11495371  0  11495371          NaN             NaN                  NaN   \n",
       "1377936   0   1377936          NaN             NaN                  NaN   \n",
       "\n",
       "                            title               touched missing  \n",
       "15789                   Cambridge  2021-08-02T19:50:20Z     NaN  \n",
       "-1            Cambridge City F.C.                   NaN          \n",
       "-2          Chesterton, Cambridge                   NaN          \n",
       "-3        City Ground (Cambridge)                   NaN          \n",
       "-4                     Gerri Bird                   NaN          \n",
       "...                           ...                   ...     ...  \n",
       "40398                        York                   NaN     NaN  \n",
       "10300                      Écosse                   NaN     NaN  \n",
       "27816                   Édimbourg                   NaN     NaN  \n",
       "11495371      Église Saint-Bene't                   NaN     NaN  \n",
       "1377936                États-Unis                   NaN     NaN  \n",
       "\n",
       "[24193 rows x 13 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contentmodel</th>\n",
       "      <th>langlinks</th>\n",
       "      <th>lastrevid</th>\n",
       "      <th>length</th>\n",
       "      <th>links</th>\n",
       "      <th>ns</th>\n",
       "      <th>pageid</th>\n",
       "      <th>pagelanguage</th>\n",
       "      <th>pagelanguagedir</th>\n",
       "      <th>pagelanguagehtmlcode</th>\n",
       "      <th>title</th>\n",
       "      <th>touched</th>\n",
       "      <th>missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15789</th>\n",
       "      <td>wikitext</td>\n",
       "      <td>[{'lang': 'af', '*': 'Cambridge'}, {'lang': 'a...</td>\n",
       "      <td>179254172</td>\n",
       "      <td>17453</td>\n",
       "      <td>[{'ns': 0, 'title': '1025'}, {'ns': 0, 'title'...</td>\n",
       "      <td>0</td>\n",
       "      <td>15789</td>\n",
       "      <td>fr</td>\n",
       "      <td>ltr</td>\n",
       "      <td>fr</td>\n",
       "      <td>Cambridge</td>\n",
       "      <td>2021-08-02T19:50:20Z</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cambridge City F.C.</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chesterton, Cambridge</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>City Ground (Cambridge)</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gerri Bird</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40398</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>40398</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>York</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10300</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>10300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Écosse</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27816</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>27816</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Édimbourg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11495371</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'ns': 0, 'title': 'Accolade (architecture)'}...</td>\n",
       "      <td>0</td>\n",
       "      <td>11495371</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Église Saint-Bene't</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1377936</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1377936</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>États-Unis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24193 rows × 13 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 89
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "source": [
    "result2 = result.groupby(['pageid','title'])['links'].apply(lambda x: x + x).reset_index()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "source": [
    "result2"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         index                                              links\n",
       "0        15789  [{'ns': 0, 'title': '1025'}, {'ns': 0, 'title'...\n",
       "1        15789                                                NaN\n",
       "2        15789                                                NaN\n",
       "3        15789                                                NaN\n",
       "4        15789                                                NaN\n",
       "...        ...                                                ...\n",
       "23216  1377936                                                NaN\n",
       "23217  1377936                                                NaN\n",
       "23218  1377936                                                NaN\n",
       "23219  1377936                                                NaN\n",
       "23220  1377936                                                NaN\n",
       "\n",
       "[23221 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15789</td>\n",
       "      <td>[{'ns': 0, 'title': '1025'}, {'ns': 0, 'title'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15789</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15789</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15789</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15789</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23216</th>\n",
       "      <td>1377936</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23217</th>\n",
       "      <td>1377936</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23218</th>\n",
       "      <td>1377936</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23219</th>\n",
       "      <td>1377936</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23220</th>\n",
       "      <td>1377936</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23221 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 119
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "source": [
    "result2.iloc[50]['links']"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "metadata": {},
     "execution_count": 112
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "source": [
    "if 'nan' in result2: result2.remove('nan')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "source": [
    "result2"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       pageid                                 title  \\\n",
       "0         269     Alphabet phonétique international   \n",
       "1        1348                            Héraldique   \n",
       "2        1367                               Hongrie   \n",
       "3        1490                       Irlande du Nord   \n",
       "4        1712               Liste des pays du monde   \n",
       "..        ...                                   ...   \n",
       "210  13226163                                Sawtry   \n",
       "211  13230180               Yaxley (Cambridgeshire)   \n",
       "212  13793011                         Kettle's Yard   \n",
       "213  14131764     Lord Lieutenant du Cambridgeshire   \n",
       "214  14255958  Liste des codes AITA des aéroports/C   \n",
       "\n",
       "                                                 links  \n",
       "0    [{'ns': 0, 'title': '1886'}, {'ns': 0, 'title'...  \n",
       "1    [{'ns': 0, 'title': '1806'}, {'ns': 0, 'title'...  \n",
       "2    nan,[{'ns': 0, 'title': '.hu'}, {'ns': 0, 'tit...  \n",
       "3    nan,nan,nan,nan,[{'ns': 0, 'title': '12 juille...  \n",
       "4    nan,nan,nan,nan,nan,[{'ns': 0, 'title': 'Abkha...  \n",
       "..                                                 ...  \n",
       "210  nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,na...  \n",
       "211  nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,na...  \n",
       "212  nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,na...  \n",
       "213  nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,na...  \n",
       "214  nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,na...  \n",
       "\n",
       "[215 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pageid</th>\n",
       "      <th>title</th>\n",
       "      <th>links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>269</td>\n",
       "      <td>Alphabet phonétique international</td>\n",
       "      <td>[{'ns': 0, 'title': '1886'}, {'ns': 0, 'title'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1348</td>\n",
       "      <td>Héraldique</td>\n",
       "      <td>[{'ns': 0, 'title': '1806'}, {'ns': 0, 'title'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1367</td>\n",
       "      <td>Hongrie</td>\n",
       "      <td>nan,[{'ns': 0, 'title': '.hu'}, {'ns': 0, 'tit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1490</td>\n",
       "      <td>Irlande du Nord</td>\n",
       "      <td>nan,nan,nan,nan,[{'ns': 0, 'title': '12 juille...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1712</td>\n",
       "      <td>Liste des pays du monde</td>\n",
       "      <td>nan,nan,nan,nan,nan,[{'ns': 0, 'title': 'Abkha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>13226163</td>\n",
       "      <td>Sawtry</td>\n",
       "      <td>nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>13230180</td>\n",
       "      <td>Yaxley (Cambridgeshire)</td>\n",
       "      <td>nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>13793011</td>\n",
       "      <td>Kettle's Yard</td>\n",
       "      <td>nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>14131764</td>\n",
       "      <td>Lord Lieutenant du Cambridgeshire</td>\n",
       "      <td>nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>14255958</td>\n",
       "      <td>Liste des codes AITA des aéroports/C</td>\n",
       "      <td>nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,nan,na...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>215 rows × 3 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 101
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}