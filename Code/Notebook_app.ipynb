{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup \n",
    "from flask import Flask, render_template, request\n",
    "import os\n",
    "import pygraphviz as pgv\n",
    "from pyvis.network import Network\n",
    "from itertools import chain\n",
    "import collections \n",
    "import networkx as nx\n",
    "import requests\n",
    "import json\n",
    "# use dynetx for dynamic network visualization? -- when I can download and incoporate revision history? \n",
    "\n",
    "PATH = \"/home/teijehidde/Documents/Git Blog and Coding/Comparing Wikipedia Knowledge Networks (Network Analysis Page links)/Code/\"\n",
    "DATA_FILE = \"networkdataTEST.json\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: download data node_title from Wikimedia API and save to json file.  \n",
    "def downloadNetwork(node_title, language = \"en\"): # other language are fr, nl, de. - ONLY ONE LANGUAGE CAN BE DEFINED HERE! \n",
    "\n",
    "    # setup and load existing data node.\n",
    "    API_ENDPOINT = \"https://\" + language + \".wikipedia.org/w/api.php\" # fr.wikipedia.org; https://en.wikipedia.org\n",
    "    wiki_data = []\n",
    "\n",
    "    # step 1: download data on the central (Ego) node of the network. \n",
    "    # setup API query and initial API call \n",
    "    S = requests.Session()\n",
    "    PARAMS = {\n",
    "        \"action\": \"query\",\n",
    "        \"titles\": node_title,\n",
    "        \"prop\": \"links|info|langlinks\",\n",
    "        \"plnamespace\": 0, \n",
    "        \"pllimit\": 500,\n",
    "        \"lllimit\": 500, \n",
    "        \"format\": \"json\"\n",
    "    }\n",
    "    response = S.get(url=API_ENDPOINT, params=PARAMS)\n",
    "    wiki_data.append(response.json())\n",
    "    \n",
    "    # Continue API call until all data on ego node has been downloaded. \n",
    "    while 'continue' in wiki_data[-1].keys():\n",
    "\n",
    "        PARAMS[\"plcontinue\"] = wiki_data[-1]['continue']['plcontinue']\n",
    "\n",
    "        response = S.get(url=API_ENDPOINT, params=PARAMS)\n",
    "        wiki_data.append(response.json())\n",
    "    \n",
    "    # step 2: use generator to download data on all additional nodes. \n",
    "    # setup API query for first generator API call (used to download data on all pages that are linked to node_title) \n",
    "    S = requests.Session()\n",
    "    PARAMS = {\n",
    "        \"action\": \"query\",\n",
    "        \"generator\": \"links\",\n",
    "        \"titles\": node_title,\n",
    "        \"gplnamespace\": 0, \n",
    "        \"gpllimit\": 500, \n",
    "        \"plnamespace\": 0,\n",
    "        \"pllimit\": 500, \n",
    "        \"prop\": \"links\",\n",
    "        \"format\": \"json\"\n",
    "    }\n",
    "    response = S.get(url=API_ENDPOINT, params=PARAMS)\n",
    "    wiki_data.append(response.json())\n",
    "\n",
    "    # Continue API call until all data on network is downloaded. \n",
    "    while 'continue' in wiki_data[-1].keys():\n",
    "\n",
    "        PARAMS[\"plcontinue\"] = wiki_data[-1]['continue']['plcontinue']\n",
    "        response = S.get(url=API_ENDPOINT, params=PARAMS)\n",
    "        wiki_data.append(response.json())\n",
    "    \n",
    "    # step 3: transforming and saving data to JSON file.    \n",
    "    # Loading previously saved link data.\n",
    "    with open(PATH + DATA_FILE) as json_file:\n",
    "        network_data = json.load(json_file)\n",
    "    \n",
    "    # transforming data from API into unified dictionary. \n",
    "    for item in wiki_data:\n",
    "        for node in list(item['query']['pages'].keys()):\n",
    "            node_data = {'node_ID': node, 'title': item['query']['pages'][node]['title'], 'links': [], 'ego': [], 'language': language, 'AvailableLanguages': []} \n",
    "\n",
    "            if node in network_data.keys(): \n",
    "                node_data = network_data[node]\n",
    "\n",
    "            if 'links' in item['query']['pages'][node].keys():\n",
    "                for link in item['query']['pages'][node]['links']: \n",
    "                    node_data['links'].append(link['title'])\n",
    "            node_data['links'] = list(set(node_data['links']))\n",
    "\n",
    "            node_data['ego'].append(node_title)\n",
    "            node_data['ego'] = list(set(node_data['ego']))\n",
    "            \n",
    "            if 'langlinks' in item['query']['pages'][node].keys():\n",
    "                node_data['AvailableLanguages'] = item['query']['pages'][node]['langlinks']\n",
    "                        \n",
    "            network_data[language + node] = node_data\n",
    "\n",
    "    # Saving data to json file. \n",
    "    try: \n",
    "        with open(PATH + DATA_FILE, 'w') as outfile:\n",
    "            json.dump(network_data, outfile)\n",
    "            print(\"Data succesfully saved. Wiki network name: \" + node_title + \"; downloaded in language: \" + language + \".\")\n",
    "\n",
    "    except: \n",
    "        print(\"Something went wrong. Check code.\")\n",
    "\n",
    "# optional, for debugging: \n",
    "#    finally:\n",
    "#        return wiki_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: download additional languages of ego network.\n",
    "def downloadAdditionalLanguage(node_title, original_language = \"en\", requested_languages = []): # \"de\", \"fr\", \"nl\"\n",
    "\n",
    "    # download data fro JSON file. \n",
    "    with open(PATH + DATA_FILE) as json_file:\n",
    "        network_data = json.load(json_file)\n",
    "    \n",
    "    # make a list of the language that are available for requested page. \n",
    "    availabe_langs_titles = [v['AvailableLanguages'] for (k,v) in network_data.items() if v['title'] == node_title if v['language'] == original_language][0]\n",
    "    list_available_langs = []\n",
    "    for item in availabe_langs_titles: \n",
    "        list_available_langs.append(item['lang'])\n",
    "\n",
    "    # If no languages are requested, the function shows available languages. \n",
    "    if requested_languages == []:\n",
    "        print('The wikipedia page is available in the following languages:')         \n",
    "        print(list_available_langs)\n",
    "    \n",
    "    # Goes through avialble languages of a wikipedia page, and downloads those that were requested (using the downloadNetwork() function). \n",
    "    else:\n",
    "        for item in availabe_langs_titles: \n",
    "            if item['lang'] in requested_languages: \n",
    "                downloadNetwork(node_title = item['*'], language = item['lang'])\n",
    "    \n",
    "    print(\"Download of additional languages finished.\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Data succesfully saved. Wiki network name: Michael_Lee_(basketball,_born_1986); downloaded in language: en.\n"
     ]
    }
   ],
   "source": [
    "# TEST \n",
    "# downloadNetwork('Michael_Lee_(basketball,_born_1986)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Data succesfully saved. Wiki network name: Anoviara; downloaded in language: fr.\n",
      "Data succesfully saved. Wiki network name: Anoviara; downloaded in language: it.\n",
      "Download of additional languages finished. If no networks were downloaded, check if pages are available in requested language(s).\n"
     ]
    }
   ],
   "source": [
    "# TEST \n",
    "# downloadAdditionalLanguage(node_title='Michael_Lee_(basketball,_born_1986)', requested_languages = ['fr','it','de'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"set\") to str",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-182-a28131d58bc9>\u001b[0m in \u001b[0;36mdownloadAdditionalLanguage\u001b[0;34m(node_title, original_language, requested_languages)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mavailabe_langs_titles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'AvailableLanguages'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnetwork_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnode_title\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'language'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0moriginal_language\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-182-a28131d58bc9>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mavailabe_langs_titles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'AvailableLanguages'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnetwork_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnode_title\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'language'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0moriginal_language\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'AvailableLanguages'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-183-ae228c07dec8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# TEST\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdownloadAdditionalLanguage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_title\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Japan'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequested_languages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'fr'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'it'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'de'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-182-a28131d58bc9>\u001b[0m in \u001b[0;36mdownloadAdditionalLanguage\u001b[0;34m(node_title, original_language, requested_languages)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mego_networks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ego'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnetwork_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mego_networks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mego_networks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Call for available language failed. Is this node an ego node of network? Available ego nodes are: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mego_networks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mlist_available_langs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mavailabe_langs_titles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"set\") to str"
     ]
    }
   ],
   "source": [
    "# TEST\n",
    "downloadAdditionalLanguage(node_title='Japan', requested_languages = ['fr','it','de'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from here on scripts to use in runtime. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from json file. \n",
    "with open(PATH + DATA_FILE) as json_file:\n",
    "        network_data = json.load(json_file)\n",
    "\n",
    "# create object that lists available networks \n",
    "ego_networks = [(v['ego']) for (k,v) in network_data.items()]\n",
    "ego_networks = set(list(chain(*ego_networks)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate class Node. \n",
    "class WikiNode:\n",
    "    def __init__(self,node_title):\n",
    "        self.node_title = node_title\n",
    "        self.node_links = network_data[node_title]['links']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate class WikiNetwork\n",
    "class WikiNetwork(WikiNode):\n",
    "    \n",
    "    def __init__(self,node_title):\n",
    "        # initiate network as class WikiNode, add additional attributes for class WikiNetwork \n",
    "        if node_title in available_networks:\n",
    "            WikiNode.__init__(self, node_title)\n",
    "            self.network_nodes = []\n",
    "            self.network_edges = [] \n",
    "            self.network_status = []\n",
    "        if node_title not in available_networks: \n",
    "            print(\"Node not available. Download using download Network function.\") \n",
    "        \n",
    "        # Links are here used to build the network.  \n",
    "        node_title_links = [v['title'] for (k,v) in network_data.items() if v['ego'] == [node_title]]\n",
    "        self.node_links.append(node_title_links)\n",
    "\n",
    "        for link in self.node_links:\n",
    "            Node2 = WikiNode(link)\n",
    "            purged_nodes = [x for x in Node2.node_links if x in self.node_links]\n",
    "            purged_edges = []\n",
    "            for purged_node in purged_nodes:\n",
    "                purged_edges.append((link,purged_node))  \n",
    "            self.network_nodes = self.network_nodes + purged_nodes\n",
    "            self.network_edges = self.network_edges + purged_edges                             \n",
    "        self.nodes_count = Counter(self.network_nodes)\n",
    "        print(\"Data Succesfully loaded.\")\n",
    "\n",
    "    def getStatusNetwork(self):     \n",
    "        return Counter(self.network_status)\n",
    "\n",
    "    def getNodesEdges(self,threshold):\n",
    "        selected_nodes = [k for k,v in self.nodes_count.items() if float(v) >= threshold]\n",
    "        selected_edges = [(a,b) for a,b in self.network_edges if a in selected_nodes and b in selected_nodes]\n",
    "\n",
    "        nodes_network = []\n",
    "        for node in selected_nodes:\n",
    "            node_tuple = (node, {\"name\": node})\n",
    "            nodes_network.append(node_tuple)\n",
    "\n",
    "        return (nodes_network,selected_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawGraph(WikiNodesEdges):\n",
    "    \n",
    "    Graph = nx.Graph()\n",
    "\n",
    "    # Graph.add_nodes_from(WikiNodesEdges[0])\n",
    "    Graph.add_edges_from(WikiNodesEdges[1])\n",
    "\n",
    "    netdraw = Network('2000px', '2000px')\n",
    "    netdraw.from_nx(Graph)\n",
    "    netdraw.barnes_hut()\n",
    "\n",
    "    netdraw.show(\"wikigraphEN.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FROM HERE RUN TIME STARTS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "'plcontinue'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-159-c44288169d36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdownloadNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'London'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-153-37ad4b197ae3>\u001b[0m in \u001b[0;36mdownloadNetwork\u001b[0;34m(node_title, language)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;34m'continue'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwiki_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mPARAMS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"plcontinue\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwiki_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'continue'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'plcontinue'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAPI_ENDPOINT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPARAMS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'plcontinue'"
     ]
    }
   ],
   "source": [
    "downloadNetwork('London')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "'Netrin'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-151-ae814d5f127d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWikiNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Netrin'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-147-a46d0f25afec>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_title)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# initiate network as class WikiNode, add additional attributes for class WikiNetwork\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnode_title\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mavailable_networks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mWikiNode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_title\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork_edges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-130-6145f85cbf10>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_title)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnode_title\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_title\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode_title\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_links\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_title\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'links'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'Netrin'"
     ]
    }
   ],
   "source": [
    "test = WikiNetwork('Netrin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup objects \n",
    "\n",
    "\n",
    "wiki_dicts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup API query and initial API call \n",
    "node_title = \"\"\n",
    "S = requests.Session()\n",
    "PARAMS = {\n",
    "    \"action\": \"query\",\n",
    "    \"generator\": \"links\",\n",
    "    \"titles\": node_title,\n",
    "    \"gplnamespace\": 0, \n",
    "    \"gpllimit\": 500, \n",
    "    \"plnamespace\": 0, \n",
    "    \"pllimit\": 500, \n",
    "    \"prop\": \"links\",\n",
    "    \"format\": \"json\"\n",
    "}\n",
    "response = S.get(url=API_ENDPOINT, params=PARAMS)\n",
    "wiki_dicts.append(response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "'title'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-433-c2bbe87b913e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"query\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"pages\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'title'"
     ]
    }
   ],
   "source": [
    "test[\"query\"][\"pages\"]['title'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue API call until all data on network is downloaded. \n",
    "node_title = 'Robert_L._Spencer'\n",
    "language = 'en'\n",
    "wiki_data = test[1]\n",
    "network_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for item in wiki_data:\n",
    "    for node in list(item['query']['pages'].keys()):\n",
    "        node_data = {'node_ID': node, \"title\": item['query']['pages'][node]['title'], 'links': [], 'ego': [], \"language\": []} \n",
    "\n",
    "        if node in network_data.keys(): \n",
    "            node_data = network_data[node]\n",
    "\n",
    "        node_data['ego'].append(node_title)\n",
    "        node_data['language'].append(language)\n",
    "        if 'links' in item['query']['pages'][node].keys():\n",
    "            for link in item['query']['pages'][node]['links']: \n",
    "                node_data['links'].append(link['title'])\n",
    "        \n",
    "        node_data['ego'] = list(set(node_data['ego']))\n",
    "        node_data['language'] = list(set(node_data['language']))\n",
    "        node_data['links'] = list(set(node_data['links']))\n",
    "        \n",
    "        network_data[node] = node_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PATH + DATA_FILE, 'w') as outfile:\n",
    "    json.dump(network_data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_links = set()\n",
    "\n",
    "for link in wiki_dicts[0]['query']['pages']['14019']['links']:\n",
    "    wiki_links.add(link['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'ALAM',\n",
       " 'Alliance of Automobile Manufacturers',\n",
       " 'American Society of Mechanical Engineers',\n",
       " 'Automobile',\n",
       " 'BTU',\n",
       " 'Basal rate',\n",
       " 'Bibcode (identifier)',\n",
       " 'Bore (engine)',\n",
       " 'Brake specific fuel consumption',\n",
       " 'Chevrolet Corvette',\n",
       " 'Chrysler FirePower engine',\n",
       " 'Citroën 2CV',\n",
       " 'DIN',\n",
       " 'Deutsches Institut für Normung',\n",
       " 'Diesel engine',\n",
       " 'Directional drilling',\n",
       " 'Directive 80/1269/EEC',\n",
       " 'Doi (identifier)',\n",
       " 'Draft horse',\n",
       " 'Draft horses',\n",
       " 'Drawbar (haulage)',\n",
       " 'Drilling mud',\n",
       " 'Drilling rig',\n",
       " 'Dynamometer',\n",
       " 'Dynamometer car',\n",
       " 'Electric motor',\n",
       " 'Encyclopædia Britannica Eleventh Edition',\n",
       " 'Ente Nazionale Italiano di Unificazione',\n",
       " 'European units of measurement directives',\n",
       " 'Exhaust manifold',\n",
       " 'Flywheel',\n",
       " 'Foot (unit)',\n",
       " 'Foot-pound (energy)',\n",
       " 'Force',\n",
       " 'GM LS engine',\n",
       " 'General Conference on Weights and Measures',\n",
       " 'Germany',\n",
       " 'HMS Agincourt (1865)',\n",
       " 'HMS Albacore (1856)',\n",
       " 'HMS Bellerophon (1865)',\n",
       " 'HMS Dee (1832)',\n",
       " 'HMS Harpy (1845)',\n",
       " 'HMS Hector (1862)',\n",
       " 'HMS Jackal (1844)',\n",
       " 'HMS Locust (1840)',\n",
       " 'HMS Monarch (1868)',\n",
       " 'HMS Penelope (1867)',\n",
       " 'HMS Porcupine (1844)',\n",
       " 'HMS Rhadamanthus (1832)',\n",
       " 'HMS Simoom (1849)',\n",
       " 'HMS Spiteful (1842)',\n",
       " 'HMS Spitfire (1845)',\n",
       " 'HMS Supply (1854)',\n",
       " 'Hoepli',\n",
       " 'Horse mill',\n",
       " 'Horsepower',\n",
       " 'Horsepower (disambiguation)',\n",
       " 'Horsepower-hour',\n",
       " 'Human-powered equipment',\n",
       " 'Hydraulic machinery',\n",
       " 'ISBN (identifier)',\n",
       " 'ISO 14396',\n",
       " 'ISO 1585',\n",
       " 'ISO 2534',\n",
       " 'ISO 4106',\n",
       " 'ISO 4164',\n",
       " 'ISO 8178',\n",
       " 'ISO 9000',\n",
       " 'ISO 9249',\n",
       " 'Indicator diagram',\n",
       " 'International Organization for Standardization',\n",
       " 'International System of Units',\n",
       " 'International avoirdupois pound',\n",
       " 'Iowa State Fair',\n",
       " 'Italy',\n",
       " 'Jaguar (car)',\n",
       " 'James Watt',\n",
       " 'James Watt (inventor)',\n",
       " 'John Smeaton',\n",
       " 'John Theophilus Desaguliers',\n",
       " 'Joule',\n",
       " 'Kenya Colony',\n",
       " 'Kilogram',\n",
       " 'Kilogram-force',\n",
       " 'Kilowatt',\n",
       " 'Lancaster County, Pennsylvania',\n",
       " 'Locomotive',\n",
       " 'Mean effective pressure',\n",
       " 'Metre',\n",
       " 'Minute',\n",
       " 'National Automobile Chamber of Commerce',\n",
       " 'Nature (journal)',\n",
       " 'Newcomen steam engine',\n",
       " 'Newton (unit)',\n",
       " 'Orders of magnitude (power)',\n",
       " 'Original equipment manufacturer',\n",
       " 'PMID (identifier)',\n",
       " 'Philadelphia Centennial Exhibition',\n",
       " 'Piston engines',\n",
       " 'Poncelet',\n",
       " 'Popular Mechanics',\n",
       " 'Pound (mass)',\n",
       " 'Pound per square inch',\n",
       " 'Pound-foot (torque)',\n",
       " 'Power (physics)',\n",
       " 'Power at rail',\n",
       " 'Prony brake',\n",
       " 'Railway',\n",
       " 'Railway car',\n",
       " 'Revolutions per minute',\n",
       " 'Rotational speed',\n",
       " 'Rounding',\n",
       " 'Royal Automobile Club',\n",
       " 'Rule of thumb',\n",
       " 'S2CID (identifier)',\n",
       " 'SI',\n",
       " 'Scottish people',\n",
       " 'Second',\n",
       " 'Society of Automotive Engineers',\n",
       " 'Standard gravity',\n",
       " 'Standards organisation',\n",
       " 'Steam',\n",
       " 'Steam boiler',\n",
       " 'Steam engine',\n",
       " 'Tax horsepower',\n",
       " 'Thomas Savery',\n",
       " 'Torque',\n",
       " 'Toyota Camry',\n",
       " 'Toyota MZ engine',\n",
       " 'Toyota Motor Corporation',\n",
       " 'Train',\n",
       " 'Truck',\n",
       " 'Turbine',\n",
       " 'Turboprop',\n",
       " 'UNECE Regulations',\n",
       " 'US gal',\n",
       " 'US gallon',\n",
       " 'Unit of measurement',\n",
       " 'Units of Measure Directive',\n",
       " 'Usain Bolt',\n",
       " 'V8 engine',\n",
       " 'Watt',\n",
       " 'Wikisource',\n",
       " 'William Henry White',\n",
       " 'Work (physics)'}"
      ]
     },
     "metadata": {},
     "execution_count": 512
    }
   ],
   "source": [
    "wiki_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 502
    }
   ],
   "source": [
    "'links' in wiki_dicts[0]['query']['pages']['14019'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Alliance of Automobile Manufacturers'"
      ]
     },
     "metadata": {},
     "execution_count": 507
    }
   ],
   "source": [
    "wiki_dicts[0]['query']['pages']['14019']['links'][1]['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.update(wiki_dicts[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'keys'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-485-3083fb768831>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwiki_dicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'query'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pages'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "for item in list(wiki_dicts): \n",
    "    for page in item['query']['pages']: \n",
    "        print(len(page.keys())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict_keys(['pageid', 'ns', 'title', 'links'])"
      ]
     },
     "metadata": {},
     "execution_count": 498
    }
   ],
   "source": [
    "wiki_dicts[0]['query']['pages']['14019'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "int() argument must be a string, a bytes-like object or a number, not 'list'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-497-d199ca82beab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwiki_dicts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'query'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pages'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a number, not 'list'"
     ]
    }
   ],
   "source": [
    "test = int(list(wiki_dicts[0]['query']['pages'].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "Object of type set is not JSON serializable",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-521-e08ceb4cb7fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mDATA_FILE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3.8/json/__init__.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;31m# could accelerate with writelines in some versions of Python, at\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;31m# a debuggability cost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmarkers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode_dict\u001b[0;34m(dct, _current_indent_level)\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/json/encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[0;34m(o, _current_indent_level)\u001b[0m\n\u001b[1;32m    436\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Circular reference detected\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0mmarkers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmarkerid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m             \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmarkers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/json/encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \"\"\"\n\u001b[0;32m--> 179\u001b[0;31m         raise TypeError(f'Object of type {o.__class__.__name__} '\n\u001b[0m\u001b[1;32m    180\u001b[0m                         f'is not JSON serializable')\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type set is not JSON serializable"
     ]
    }
   ],
   "source": [
    "with open(PATH + DATA_FILE, 'w') as outfile:\n",
    "    json.dump(network_data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_data = {'node_ID': \"node\", 'links': \"links_wiki\", 'ego': set(), \"language\": set()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "set"
      ]
     },
     "metadata": {},
     "execution_count": 439
    }
   ],
   "source": [
    "type(node_data['ego'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'1256|0|Claudius'"
      ]
     },
     "metadata": {},
     "execution_count": 246
    }
   ],
   "source": [
    "data_wiki_temp['continue']['plcontinue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'set' object is not subscriptable",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-470-4128a4867ac4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_wiki\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'query'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pages'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'12789341'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'set' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "data_wiki['query']['pages']['12789341'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = \"en\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_ENDPOINT = \"https://\" + language + \".wikipedia.org/w/api.php\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'https://en.wikipedia.org/w/api.php'"
      ]
     },
     "metadata": {},
     "execution_count": 344
    }
   ],
   "source": [
    "API_ENDPOINT\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "execution_count": 88
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}