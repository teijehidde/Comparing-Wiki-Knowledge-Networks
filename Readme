# for now this is an overview and issue tracker. 

Aim of App: 
- Compare networks of wikipedia pages on one topic between multiple languages.



TODOs 
1: Create a WikiGraph class, based on networkx nx.Graph instance. It should have method to call status graph (no. of nodes, edges, etc; analysis on individual nodes and comeplete graph; and include visualisation of graph. It should also be possible to export csv data on graph. All this should be build on networkx, pyvis and numpy. 
2: Revise API call to act at network (not node) level, and based completely on generators. -- see website from wikipedia. Also consider implementing zipping. 
3: API should check what language a topic is available in. 
4: Restructure (again) how data is saved. a) The 'plcontinue value' should NOT be linked to node (similar to how wikimedia treats it). b) Implement timestamp c) save the wikipedia version (english, french, arabic) that data is from. 
5: Start playting around with comparing knowledge networks around topics _in different languages_. Cross case comparison on same topic. 
6: Start playting with Django for building interacting website to visualize descriptive analysis. On the face of it Django seems more straighforward than Flask. 
7: -- later -- incorporate 'revision' in data that is downloaded. 
8: -- later -- work with dynamic network visualisations and analysis. They do exist in Python, but do not know how stable / efficient they are yet.  
9: While doing this, do not forget to push to git & keep up adding notes to code. Also for myself.. 





